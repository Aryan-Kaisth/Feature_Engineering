{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature-Engineering"
      ],
      "metadata": {
        "id": "7jNXcfgKikYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 1:** What is a parameter?\n",
        "\n",
        "**Answer:** A parameter refers to a configuration or value that is learned from the training data during the model training process. Parameters are internal variables that the model adjusts in order to make accurate predictions. They define the model's structure and behavior."
      ],
      "metadata": {
        "id": "cBFTouXPx3V3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 2:** What is correlation?\n",
        "\n",
        " What does negative correlation mean?\n",
        "\n",
        "\n",
        "**Answer:** Correlation is a statistical measure that describes the relationship between two variables. It indicates the strength and direction of the linear relationship between the variables.\n",
        "\n",
        "A negative correlation means if one variable increases, the other variable tends to decrease, and vice versa."
      ],
      "metadata": {
        "id": "OxfvNWQRyhbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 3:**  Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "\n",
        "**Answer:** Machine Learning (ML) is a subset of artificial intelligence (AI) that enables computers to learn from data and improve from experience without being explicitly programmed.\n",
        "\n",
        "**Main components in Machine Learning:-**\n",
        "\n",
        "`Data`: The foundational element in ML, consisting of features (input variables)\n",
        "\n",
        "and labels (output variables). Quality and quantity of data are crucial for building effective models.\n",
        "\n",
        "`Algorithms`: Mathematical methods used to build models, such as Linear Regression, Decision Trees, and Neural Networks. These algorithms learn patterns from data.\n",
        "\n",
        "`Model`: The mathematical representation built by training an algorithm on data. It predicts or classifies based on learned patterns.\n",
        "\n",
        "`Training Data`: A dataset used to teach the algorithm by providing examples of input-output pairs.\n",
        "\n",
        "`Testing Data`: A separate dataset used to evaluate how well the trained model perform on unseen data.\n",
        "\n",
        "`Features`: Input variables that help predict the outcome. Examples: age, income, or house size.\n",
        "\n",
        "`Labels`: The target outcome or result the model is trying to predict."
      ],
      "metadata": {
        "id": "EVHCPwJuyuy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 4:**  How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "**Answer:** The loss value helps determine how well the model is performing. It measures the difference between the model's predictions and the actual values. A lower loss value indicates better model performance, meaning the model's predictions are closer to the actual outcomes. Conversely, a higher loss value suggests that the model's predictions are farther off, indicating it needs improvement.\n",
        "\n",
        "MSE, MAE, RMSE, R^2 and Adjusted R^2 are some loss functions."
      ],
      "metadata": {
        "id": "Ma41d_MDyvY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 5:** What are continuous and categorical variables?\n",
        "\n",
        "**Answer:** `Continuous variables` are quantitative variables that can take an infinite number of values within a given range.\n",
        "\n",
        "`Categorical variables` are qualitative variables that represent categories or groups."
      ],
      "metadata": {
        "id": "B8CXc3ANywty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 6:** How do we handle categorical variables in Machine Learning? What are the common t\n",
        " echniques?\n",
        "\n",
        "**Answer:** To handle categorical variables in Machine Learning, we need to convert them into numerical values since most algorithms require numerical input. The common techniques are:\n",
        "\n",
        "1. `One-Hot Encoding`: Converts each category into a new binary column (0 or 1).\n",
        "\n",
        "2. `Label Encoding`: Converts each category into a unique integer.\n",
        "\n",
        "3. `Target Encoding`: Involves encoding categories based on the mean of the target variable for each category.\n",
        "\n",
        "These techniques help the model understand categorical data, allowing it to make accurate predictions."
      ],
      "metadata": {
        "id": "KyhNKFEhyyHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 7:** What do you mean by training and testing a dataset?\n",
        "\n",
        "**Answer:**  **a)** Training a dataset means using a part of the data to train the ML model.\n",
        "\n",
        "**b)** **Testing dataset** is unseen data on which the ML model is tested on."
      ],
      "metadata": {
        "id": "MgEO5Dv0yziA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 8:** What is sklearn.preprocessing?\n",
        "\n",
        "**Answer:** sklearn.preprocessing is a module in scikit-learn (a popular Python machine learning library) that provides several utilities and functions to transform and scale data to prepare it for machine learning algorithms.\n",
        "\n",
        "Key features of sklearn.preprocessing include:\n",
        "1. Scaling and Normalization\n",
        "2. Encoding Categorical Data"
      ],
      "metadata": {
        "id": "NZzoZRw_y0oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 9:**  What is a Test set?\n",
        "\n",
        "**Answer:** A test set is a portion of the dataset that is used to evaluate the performance of a machine learning model after it has been trained."
      ],
      "metadata": {
        "id": "7WNQe-fzy2AW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 10:** How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        " b) How do you approach a Machine Learning problem?\n",
        "\n",
        "**Answer:** b.\n",
        "1. Define the Problem: Identify the objective (classification, regression, etc.), inputs (features), and outputs (target variable).\n",
        "\n",
        "2. Collect and Prepare Data: Gather relevant data, clean it (handle missing values, outliers), and engineer features.\n",
        "\n",
        "3. Explore Data (EDA): Visualize and analyze relationships between variables, identify patterns, and calculate statistics.\n",
        "\n",
        "4. Choose the Model: Select an appropriate model based on the problem (e.g., logistic regression for classification).\n",
        "\n",
        "5. Split the Data: Divide the dataset into training and testing sets (typically 80-20% or 70-30%).\n",
        "\n",
        "6. Train the Model: Fit the selected model to the training data and tune hyperparameters.\n",
        "\n",
        "7. Evaluate the Model: Assess performance using metrics (accuracy, RMSE, etc.) and ensure the model is not overfitting or underfitting.\n",
        "\n",
        "8. Optimize the Model: Fine-tune hyperparameters and improve features if necessary."
      ],
      "metadata": {
        "id": "vnxBAep_y3aI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a.\n",
        "# Importing necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data1 = pd.DataFrame({'Feature1': [1, 2, 3, 4, 5],'Feature2': [5, 4, 3, 2, 1],'Target': [0, 1, 0, 1, 0]})\n",
        "\n",
        "# Features (X) and target (y)\n",
        "X = data1[['Feature1', 'Feature2']]  # Independent variables (features)\n",
        "y = data1['Target']  # Dependent variable (target)\n",
        "\n",
        "# Splitting the data into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the shape of the split datasets\n",
        "print(f\"Training Features Shape: {X_train.shape}\")\n",
        "print(f\"Testing Features Shape: {X_test.shape}\")\n",
        "print(f\"Training Target Shape: {y_train.shape}\")\n",
        "print(f\"Testing Target Shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WYaOqLKBFyN",
        "outputId": "b10377e8-8be1-4b8b-df7a-c685d3e2842f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features Shape: (4, 2)\n",
            "Testing Features Shape: (1, 2)\n",
            "Training Target Shape: (4,)\n",
            "Testing Target Shape: (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 11:**  Why do we have to perform EDA before fitting a model to the data?\n",
        "\n",
        "**Answer:** EDA (Exploratory Data Analysis) is crucial before fitting a model because it helps you:\n",
        "\n",
        "1. Understand the distribution of data.\n",
        "2. Identify missing values, duplicate values and outliers.\n",
        "3. Explore relationships between features and the target variable.\n",
        "4. Inform feature engineering and selection.\n",
        "5. Choose the right model based on data patterns."
      ],
      "metadata": {
        "id": "KMfc8Pqxy41X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 12:**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "jjXFfWJ0y7hW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 13:**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "SpSK5Vdiy87Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 14:**  How can you find correlation between variables in Python?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "C-W0hvVyy-kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = {'Age': [23, 25, 28, 30, 22, 27],'Salary': [45000, 50000, 60000, 70000, 40000, 65000],'Experience (Years)': [1, 2, 4, 5, 1, 3]}\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(data2)\n",
        "\n",
        "# Finding the correlation between all numerical columns\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Displaying the correlation matrix\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r43Ivl8xFLpg",
        "outputId": "1811c503-7ee5-430a-b70a-e7427aed2e4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Age    Salary  Experience (Years)\n",
            "Age                 1.000000  0.966521            0.987105\n",
            "Salary              0.966521  1.000000            0.931589\n",
            "Experience (Years)  0.987105  0.931589            1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 15:** What is causation? Explain difference between correlation and causation with an example\n",
        "\n",
        "**Answer:** Causation refers to a relationship between two variables where one variable directly affects or causes changes in the other. In other words, causation implies that changes in one variable result in changes in another.\n",
        "\n",
        "`Difference between both:`\n",
        "\n",
        "**Correlation:**\n",
        "\n",
        "Measures the strength and direction of a relationship between two variables.\n",
        "\n",
        "Does not imply one variable causes the other.\n",
        "\n",
        "Symmetric relationship:𝐴↔𝐵\n",
        "\n",
        "Example: Ice cream sales and drowning incidents are correlated (both increase in summer).\n",
        "\n",
        "**Causation:**\n",
        "\n",
        "Indicates a cause-and-effect relationship where one variable directly affects the other.\n",
        "\n",
        "Implies that changes in one variable result in changes in the other.\n",
        "\n",
        "Asymmetric relationship: 𝐴→𝐵.\n",
        "\n",
        "Example: Eating contaminated food causes food poisoning."
      ],
      "metadata": {
        "id": "I2fuJo62zDb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Question 16:**  What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "**Answer:** An optimizer is an algorithm used to minimize or maximize a model's loss function during the training process.\n",
        "Gradient Descent (GD):\n",
        "\n",
        "Description: A simple optimization algorithm that adjusts model parameters by moving in the opposite direction of the gradient (derivative) of the loss function. It does this for each parameter individually to minimize the loss function. `Eqn is hQ(x)=Q1x=Q0`\n",
        "\n",
        "Example: In linear regression, Gradient Descent adjusts the coefficients of the features iteratively to minimize the Mean Squared Error (MSE) or loss function."
      ],
      "metadata": {
        "id": "4fAGd8SvzFFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Question 17:**  What is sklearn.linear_model ?\n",
        "\n",
        "\n",
        "**Answer:** `sklearn.linear_model` is a module in the scikit-learn library that provides linear models for regression and classification tasks. These models are based on linear relationships between input features (independent variables) and the output target (dependent variable)"
      ],
      "metadata": {
        "id": "jcvlTMeCzHY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 18:**  What does model.fit() do? What arguments must be given?\n",
        "\n",
        "\n",
        "**Answer:** The `fit() method` in machine learning is used to train the model on the provided training data. It learns the patterns or relationships in the data to make predictions.\n",
        "\n",
        "Arguments for model.fit():\n",
        "\n",
        "x (Training features): This is the input data that the model uses to learn. It is usually a 2D array or a DataFrame.\n",
        "\n",
        "y (Target labels): These are the true values corresponding to the features X. It could be a 1D array or a Series."
      ],
      "metadata": {
        "id": "6qNsq47hzNtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 19:**  What does model.predict() do? What arguments must be given?\n",
        "\n",
        "\n",
        "**Answer:** The `predict()` method is used to make predictions using the trained model. After fitting the model, this method takes in new data (the test set) and generates the predicted outputs.\n",
        "\n",
        "Arguments for model.predict():\n",
        "\n",
        "x (Test features): The input data on which predictions are to be made."
      ],
      "metadata": {
        "id": "WQLsi8hpzW4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 20:**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "8PFer02izYb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Question 21:**  What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "\n",
        "**Answer:** Feature scaling refers to the process of normalizing or standardizing the range of independent variables or features in a dataset. It ensures that each feature contributes equally to the model, preventing any feature with larger numerical ranges from dominating the learning process.\n",
        "\n",
        "Types of Feature Scaling:\n",
        "\n",
        "1. Normalization (Min-Max Scaling)\n",
        "2. Standardization (Z-score Scaling)"
      ],
      "metadata": {
        "id": "xX1T6CROzam3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Question 22:**  How do we perform scaling in Python?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "1xZmEC0Yzby4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Creating a small dataset\n",
        "data3 = {'Age': [25, 30, 35, 40, 45],'Income': [40000, 50000, 60000, 70000, 80000],'Score': [88, 92, 85, 79, 95]}\n",
        "\n",
        "df = pd.DataFrame(data3)\n",
        "\n",
        "# Standardizing the data (mean = 0, std = 1)\n",
        "scaler_standard = StandardScaler()\n",
        "df_standardized = df.copy()\n",
        "df_standardized[['Age', 'Income', 'Score']] = scaler_standard.fit_transform(df[['Age', 'Income', 'Score']])\n",
        "\n",
        "# Normalizing the data (range 0-1)\n",
        "scaler_normalize = MinMaxScaler()\n",
        "df_normalized = df.copy()\n",
        "df_normalized[['Age', 'Income', 'Score']] = scaler_normalize.fit_transform(df[['Age', 'Income', 'Score']])\n",
        "\n",
        "# Displaying the results\n",
        "print(\"Original Data:\\n\", df)\n",
        "print(\"\\nStandardized Data:\\n\", df_standardized)\n",
        "print(\"\\nNormalized Data:\\n\", df_normalized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcmQ5BOuJmik",
        "outputId": "f1f594b9-8610-4062-a3de-d9b8161d2430"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "    Age  Income  Score\n",
            "0   25   40000     88\n",
            "1   30   50000     92\n",
            "2   35   60000     85\n",
            "3   40   70000     79\n",
            "4   45   80000     95\n",
            "\n",
            "Standardized Data:\n",
            "         Age    Income     Score\n",
            "0 -1.414214 -1.414214  0.035944\n",
            "1 -0.707107 -0.707107  0.754829\n",
            "2  0.000000  0.000000 -0.503220\n",
            "3  0.707107  0.707107 -1.581547\n",
            "4  1.414214  1.414214  1.293993\n",
            "\n",
            "Normalized Data:\n",
            "     Age  Income   Score\n",
            "0  0.00    0.00  0.5625\n",
            "1  0.25    0.25  0.8125\n",
            "2  0.50    0.50  0.3750\n",
            "3  0.75    0.75  0.0000\n",
            "4  1.00    1.00  1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 23:**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "MKhbPR5Fzds_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 24:**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "G-1PMSw6zfK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Question 25:**  Explain data encoding?\n",
        "\n",
        "**Answer:** Data encoding is the process of converting categorical data into numerical data.\n",
        "\n",
        "Types of data encoding:-\n",
        "\n",
        "1. **One hot Endcoding**: Converts categorical variables into binary columns, with 1 for the category's presence and 0 for absence.\n",
        "\n",
        "2. **Ordinal Encoding**: Assigns integer values to categories with a meaningful order.\n",
        "3. **Target Encoding**: Replaces categories with the mean of the target variable for each category."
      ],
      "metadata": {
        "id": "RYFKUnoQzghR"
      }
    }
  ]
}